# ELB + ASG + EBS

## Load Balancers
* Load balancers are server that forward internet traffic to multiple servers(EC2 instances) downstream
* Spread across multiple downstream instances
* Expose single point of access(DNS) to your application
* Seamlessly handle failures of downstream instances
* Do regular health checks to your instances
* Provide SSL Termination (HTTPS) for your websites
* Enforce stickiness with cookies(user talks with 1 instance)
* High availability across zones
* Separate public traffic from private traffic

## ELB
* An ELB(EC2 Load Balancer) is a managed load balancer
	* AWS guarantees that it will be working
	* AWS takes care of upgrades, maintenance, high availability
	* AWS provides only a few configuration knobs
* It costs less to setup your own load balancer but it will be more effort on your end
* Types of Load Balancer
	* Classic Load Balancer(v1 - old generation) - 2009
	* Application Load Balancer(v2 - new generation) - 2016
	* Network Load Balancer(v2 - new generation) - 2017
* You can setup an internal(private) or external(public) ELBs

### Health Checks
* Crucial for load balancers
* They enable the load balancers to know if instances it forwards traffic to are available to reply to requests
* The health check is done on a port and a route(/health)
* If the response is not 200(OK), then the instance is unhealthy


### Application Load Balancer v2
* Layer 7 - HTTP level
* Load balancing to multiple HTTP applications(target groups)
* Load balancing multiple applications on the same machines(ex: containers)
* Load balancing based on route in URL
* Load balancing based on hostname in URL
* They are awesome for microservices & container-based applications(e.g. Docker + Amazon ECS)
* Has port mapping feature to redirect to a dynamic port
* In comparison, we would need to create one Classic Load Balancer per application before. Very expensive and inefficient
* Stickiness can be enabled at the target group level
	* same request goes to same instance
	* Stickiness is directly generated by the ALB(not your application)
* ALB supports HTTP/HTTPS & Websocket
* Application servers don't see the IP of the client directly
	* true IP of the client is inserted in the header `X-Forwarded-For`
	* we can also get the Port and proto `X-Forwarded-Port` and `X-Forwarded-Proto`

### Network Load Balancer v2
* Layer 4 - TCP traffic
* Forward TCP traffic to your instances
* Handle millions of request per seconds
* Support for static or elastic IP
* Less latency ~100ms (vs 400ms for ALB)
* Commonly used for extreme performance and should not be the default load balancer you choose
* Creation process are similar to ALB

### Summary

* Classic Load Balancers are deprecated
	* ALB for HTTP/HTTPS and Websockets
	* NLB for TCP
* CLB and ALB support SSL certificates and provide SSL termination
* All Load balancers have health check capability
* ALB can route based on hostname/path
* ALB is a great fit for Docker + ECS
* Any Load Balancer(CLB, ALB, NLB) has a static host name. Do not resolve and use underlying IP
* LBs can scale but not instantaneously - contact AWS for a "warm up"
* NLB directly see the client IP
* 4xx errors are client induced errors
* 5xx errors are application induced errors
	* 503 means at capacity or no registered target
* If the LB can't connect to your application, check your security groups


## Auto Scaling Groups
* Scale out (add EC2 Instances) to match an increased load
* Scale in (remove EC2 Instances) to match an decreased load
* Ensure we have a minimum and maximum number of machines running
* Automatically Register new instances to a Load balancer

## Auto Scaling Groups in AWS
* Parameters:
	* minimum size
	* actual size/desired capacity
	* maximum size
* Attributes:
	* a launch configuration
		* AMI + instance type
		* EC2 User Data
		* EBS Volumes
		* Security Groups
		* SSH Key pair
	* Min/max size/initial/desired capacity
	* Network + subnets information
	* Load balancer information
	* Scaling policies

## Auto Scaling Alarms
* It is possible to scale ASG based on CloudWatch alarms
* An alarm monitors a metric(such as Average CPU)
* Metrics are computed for the overall ASG Instances
* It is now possible to define "better" auto scaling rules that are directly managed by EC2
	* Target Average CPU Usage
	* Number of request on the ELB per instance
	* Average Network In/Out
* Auto scale using custom metrics (ex. number of connected users)
	1. Send custom metric from application on EC2 to CloudWatch(PutMetric API)
	2. Create Cloudwatch alarm to react to low/high values
	3. Use the CloudWatch alarm as the scaling policy for ASG
* Scaling policies can be on CPU, Network.. or on custom metrics or based on schedule
* ASGs use Launch Configurations and you update an ASG by providing a new launch configuration
* IAM roles attached to an ASG will get assigned to EC2 instances
* ASG for free. You pay for underlying resources being launched.
* Having instances under ASG means that if they get terminated for whatever reason, the ASG will create or restart them.
* ASG can terminate marked as unhealthy by an LB (and hence replace them)

## EBS Volume
* an EC2 machine loses its root volume (main drive) when it is manually terminated.
* Unexpected terminations might happen from time to time
* Sometimes, you need a way to store your instance data somewhere
* an **EBS**(Elastic Block Store) Volume is a network drive you can attach your instances while they run
* Allows your instances to persist data
* It's a network drive
	* uses the network to communicate so it might have latency but not too much
	* it can be detached from an EC2 instance and attached to another one quickly
* It's locked to a certain Availability Zone
	* An EBS Volume in us-east-1a cannot be attached to us-east-1b
	* To move a volume across, you need to snapshot it first
* Have provisioned capacity(size in GBs, and IOPS)
	* You get billed for all the provisioned capacity
	* You can increase the capacity

## Volume Types
* GP2 (SSD): General purpose SSD volume that balances price and performance for a wide variety of workloads
* IO1 (SSD): Highest-performance SSD for mission-critical low-latency or high-throughput workloads, very expensive
* ST1 (HDD): Low Cost HDD volume for frequently accessed, throughput-intensive workloads
* SC1 (HDD): Low Cost HDD volume for less frequently accessed workloads

EBS Volumes are characterized in:

* Size(GBs)
* Throughputs(MB/s)
* IOPS(number of IO per seconds)

## EBS Volume Resizing
* You can only increase the EBS Volumes:
	* Size(any volume type)
	* IOPS(only in IO1)
* After resizing an EBS Volume you need to repartition your drive

## EBS Snapshots
* EBS Volumes can be backed up as snapshots
* Snapshots only take the actual space of the blocks on the volume
* Snapshots are used for:
	* Backups
	* Volume migration
		* Changing volume type
		* Resizing volume down
		* Encrypt a volume
* You can also schedule snapshots

## EBS Encryption
* When you create an encrypted EBS Volume you get the following:
	* Data at rest is encrypted inside the volume
	* All the data flight moving between the instance and the volume is encrypted
	* All snapshots are also going to be encrypted
	* All volumes created from encrypted snapshots are also encrypted
* Encryption and decryption are handled transparently
* Encryption has a minimal impact in latency
* EBS Encryption leverages keys from KMS (AES-256)
* Copying an unencrypted snapshot allows encryption

## EBS vs Instance Store
* Some instance do not come with Root EBS volumes
* Instead they come with "Instance Store"
* Instance Store is physically attached to the machine
* Pros:
	* Better I/O performance
* Cons:
	* On termination, instance will be lost
	* Can't resize the instance store
	* Backups must be operated by the user
* Overall, EBS-backed instances should fit most application workloads

## EBS Summary
* EBS can be attached to only one instance at a time
* EBS are locked at the AZ level
* Migrating an EBS volumes across AZ means first backing it up(snapshot), then creating in the other AZ
* EBS backups use IO and you shouldnt run then when your application is handling a lot of traffic
* Root EBS volumes of instances get terminated by default if the EC2 instance gets terminated(you can disable that)
